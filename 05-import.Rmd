# Импорт и экспорт данных

## Рабочая директория

Любой анализ данных начинается с импорта данных. Прежде чем что-то делать, проверьте свою рабочую директорию при помощи `getwd()` ([подробнее](https://youtu.be/z7pOxe6dDG0)). Для смены можно использовать как **абсолютный**, так и **относительный** путь:

```{r eval=FALSE}
setwd("/Users/olga/R_Workflow/Text_Analysis_2023")

# искать в текущей директории
setwd("./Text_Analysis_2023")

# перейти на уровень вверх
setwd("../")
```

## Скачивание файлов из Интернета

Основная функция для скачивания файлов из Сети -- `download.file()`, которой необходимо задать в качестве аргументов url, название сохраняемого файла, иногда также метод.

Попробуем скачать датасет из [Репозитория открытых данных по русской литературе и фольклору](https://dataverse.pushdom.ru/dataverse/openlit) под названием ["Байрон в русских переводах 1810--1860-х годов"](https://dataverse.pushdom.ru/dataset.xhtml?persistentId=doi:10.31860/openlit-2019.11-R002).

```{r eval=FALSE}
url <- "https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.5072/openlit-2019.11-R002/VQRXXK"

# если url начинается с https, на Mac _может_ потребоваться указать method = "curl"
download.file(url, destfile = "files/Byron.tab") 
```

После этого в папке files появится новый файл. Получить список скачанных файлов можно при помощи `list.files()`.

```{r}
list.files("./files", pattern = "\\.tab")
```

## Чтение табличных данных

Основные функции для чтения табличных данных в базовом R - это `read.table()` и `read.csv()`.

### csv и tsv

Файл, который мы скачали, имеет расширение `.tab`. Такие файлы по структуре аналогичны файлам `.tsv` (tab separated values). Чтобы его прочитать, используем `read.table()`, указав тип разделителя:

```{r}
Byron <- read.table("files/Byron.tab", sep = "\t", header = TRUE)

head(Byron)
```

Функция `read.csv()` отличается лишь тем, что автоматически выставляет значения аргументов `sep = ","`, header = TRUE.

В диалекте tidyverse для импорта подобных файлов используется функция read_csv из пакета `readr`[^05-import-1].

[^05-import-1]: <https://r4ds.had.co.nz/data-import.html>

Вернемся к нашему датасету про буккроссинг, файлы которого имеют расширение csv. К сожалению, это не всегда гарантия того, что перед вами действительно csv:

```{r warning=FALSE, message=FALSE}
library(readr)
users <- read_csv("files/BX/BX-Users.csv", show_col_types = FALSE)
head(users)
```

Чтобы исправить дело, воспользуемся другой функцией из того же пакета:

```{r warning=FALSE}
users <- read_delim("files/BX/BX-Users.csv", delim = ";", show_col_types = FALSE)
users
```

Очевидно, это не решает всех проблем, но как справиться с оставшимися, мы рассказывали в уроке об опрятных данных.

### xls и xlsx

Не самый любимый аналитиками, но очень распространенный тип файлов. Чтобы с ним работать, нужно установить пакет `readxl` из семейства tidyverse[^05-import-2]. Это не единственный пакет для работы с Excel, но, пожалуй, самый удобный. Файл с самыми популярными на Amazon книгами можно взять [здесь](https://www.kaggle.com/datasets/palanjali007/amazons-top-50-bestselling-novels-20092020).

[^05-import-2]: <https://readxl.tidyverse.org/>

```{r}
library(readxl)
amazon <- read_excel("files/AmazonBooks.xlsx")
head(amazon)
```

Можно указать отдельные листы, которые необходимо прочитать.^[https://r4ds.hadley.nz/spreadsheets]

## Чтение текстовых данных

### txt

Для чтения текстовых файлов в базовом R есть функция `readlines()`. Аргумент `n` указывает, сколько строк прочитать; при `n = 1` функция дойдет до первого переноса строки или параграфа.

```{r}
readLines(con = "files/karamzin_liza.txt", n = 1) 
```

### doc

Если есть возможность конвертировать документ Word в простой текстовый формат, то лучше так и сделать. Если нет, то устанавливаем пакет `officer`.

```{r message=FALSE}
library(officer)
files <- list.files(path = "files", pattern = "docx") 

# read file
doc <- read_docx(paste0("files/", files[1]))
content <- docx_summary(doc) 
head(content, 2) # весь текст доступен в столбце text
```

Таким образом, однако, мы теряем все сноски. Следующий код позволяет их достать:

```{r eval=F}
library(xml2)
xml_text(xml_find_all(doc$footnotes$get(), "*"))
```

Тут уже применяются функции для работы с xml. Поэтому лишний раз подумайте, не проще ли конвертировать документ Word в .txt.

### pdf

С pdf тоже без нужды лучше не иметь дела. Но если все-таки пришлось читать pdf, для этого есть пакет `pdftools`[^05-import-3].

[^05-import-3]: <https://rpubs.com/kbodwin/pdftools>

```{r message=FALSE}
library(pdftools)

# длинющий вектор, который придется очищать от \n (новая строка)
liza <- pdf_text(pdf = "files/karamzin_liza.pdf")

# метаданные в виде списка
meta <- pdf_info(pdf = "files/karamzin_liza.pdf")
meta$created
```

Разработчики утверждают, что пакет справится и с распознаванием текста, но для этого должен быть установлен пакет `tesseract`.

```{r eval=FALSE}
install.packages("tesseract")
```

Возможно, сначала вам придется установить нужные языки. Код ниже вы можете попробовать выполнить самостоятельно, указав актуальный путь до файла.

```{r eval=F}
library(tesseract)
tesseract_download("deu")
text <- pdf_ocr_text("./files/German.pdf", language = "deu")
cat(text)
```

### png

Тот же фокус сработает и с изображениями. Но точность распознавания сильно зависит от качества картинки.

```{r}
# tesseract_download("lat")
lat <- tesseract::tesseract("lat")
text <- tesseract::ocr("./images/latin.png", engine = lat)
cat(text)
```

![](./images/latin.png)

## Архивы

### zip

Для работы с архивами есть функция `unzip()`. Полезно помнить, что большой архив не обязательно распечатывать полностью. Если выставить аргумент `list = TRUE`, то функция вернет список всех файлов в архиве, из которых можно прочитать в память лишь избранные:

```{r}
archive <- unzip("files/archive.zip", files = NULL, list = TRUE) 
archive
```

Код ниже позволяет извлечь из архива только нужный файл:

```{r eval=F}
unzip("files/archive.zip", files = "AmazonBooks.xlsx")
```

После этого файл можно прочитать в R, как указано выше.

## Структурированные данные

### json

Формат JSON (JavaScript Object Notation) предназначен для представления структурированных данных. JSON имеет шесть основных типов данных[^05-import-5]. Четыре из них - скаляры[^05-import-6]:

[^05-import-5]: <https://r4ds.hadley.nz/rectangling#json>

[^05-import-6]: Массив строк, который имеет только один элемент, также называется строковым скаляром.

-   Самый простой тип - `null` (нуль), который играет ту же роль, что и `NA` в R. Он представляет собой отсутствие данных.
-   Строка (string) похожа на строку в R, но в ней всегда должны использоваться двойные кавычки.
-   Число аналогично числам в R; поддерживается целочисленная (например, 123), десятичная (например, 123.45) или научная (например, 1,23e3) нотация. JSON не поддерживает `Inf`, `-Inf` или `NaN`.
-   Логическое значение аналогично `TRUE` и `FALSE` в R, но использует строчные буквы `true` и `false`.

Строки, числа и булевы значения в JSON очень похожи на символьные, числовые и логические векторы в R. Основное отличие заключается в том, что скаляры JSON могут представлять только одно значение. Для представления нескольких значений необходимо использовать один из двух оставшихся типов: массивы и объекты.

И массивы, и объекты похожи на списки в R, разница заключается в том, именованы они или нет. **Массив** подобен безымянному списку и записывается через `[]`. Например, `[1, 2, 3]` - это массив, содержащий 3 числа, а `[null, 1, "string", false]` - массив, содержащий ноль, число, строку и булево значение. 

**Объект** подобен именованному списку и записывается через `{}`. Имена (ключи в терминологии JSON) являются строками, поэтому должны быть заключены в кавычки. Например, {"x": 1, "y": 2} - это объект, который сопоставляет x с 1, а y -- с 2.

Загрузим небольшой файл `TBBT.json`, хранящий данные о сериале "Теория большого взрыва" ([источник](https://gist.github.com/sahithyandev/540c82170a19f97deef9e23796083f01)).


```{r message=FALSE}
library(jsonlite)

path <- "./files/TBBT.json"
tbbt <- fromJSON(txt =  path,
                 simplifyVector = T)
```

Функция `fromJSON()` вернет нам список, который мы выборочно преобразуем в тиббл:

```{r message=FALSE}
cast_tbl <- tbbt$casting %>% 
  transpose() %>% 
  map(as.character) %>% 
  as_tibble()

cast_tbl
```

Проделаем то же самое для списка эпизодов, но немного другим способом. 

```{r}
episodes_tbl <- tibble(
  episode_id = map_chr(tbbt$episode_list, pluck, "episode_id"),
  title = map_chr(tbbt$episode_list, pluck, "title"))

episodes_tbl
```

</br>

:::{.task .code}
Самостоятельно создайте тиббл, в котором будет храниться количество серий для каждого сезона.
:::


![](https://i.redd.it/brhcksszl1k61.jpg){ width="50%" }


### xml

**XML** (от англ. eXtensible Markup Language) --- расширяемый язык разметки. Слово "расширяемый" означает, что список тегов не зафиксирован раз и навсегда: пользователи могут вводить свои собственные теги и создавать так называемые **настраиваемые языки разметки** [@xml2004, 29]. Один из таких настраиваемых языков -- это **TEI** (Text Encoding Initiative), о котором будет сказано дальше.

Назначение языков разметки заключается в описании структурированных документов. Структура документа представляется в виде набора вложенных в друг друга элементов (**дерева XML**). У элементов есть открывающие и закрывающие теги. 

Все составляющие части документа обобщаются в пролог и корневой элемент. **Корневой элемент** — обязательная часть документа, в которую вложены все остальные элементы. **Пролог** может включать объявления, инструкции обработки, комментарии.

В правильно сформированном XML открывающий и закрывающий тег вложенного элемента всегда находятся внутри одного родительского элемента.

Создадим простой XML из строки. Сначала идет инструкция по обработке XML (со знаком вопроса), за ней следует объявление типа документа (с восклицательным знаком) и открывающий тег корневого элемента. В этот корневой элемент вложены все остальные элементы.

```{r}
string_xml <- '<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE recipe>
<recipe name="хлеб" preptime="5min" cooktime="180min">
   <title>
      Простой хлеб
   </title>
   <composition>
      <ingredient amount="3" unit="стакан">Мука</ingredient>
      <ingredient amount="0.25" unit="грамм">Дрожжи</ingredient>
      <ingredient amount="1.5" unit="стакан">Тёплая вода</ingredient>
   </composition>
   <instructions>
     <step>
        Смешать все ингредиенты и тщательно замесить. 
     </step>
     <step>
        Закрыть тканью и оставить на один час в тёплом помещении. 
     </step>
     <step>
        Замесить ещё раз, положить на противень и поставить в духовку.
     </step>
   </instructions>
</recipe>'
```

Для работы с xml понадобится установить одноименную библиотеку. Функция `xmlTreeParse()` создаст R-структуру, представляющую дерево XML.

```{r}
library(XML)
doc <- xmlTreeParse(string_xml)
class(doc)
```

Функция xmlRoot позволяет извлечь корневой элемент вместе со всеми детьми. 

```{r}
rootnode <- xmlRoot(doc)
rootnode
```
 
Если документ большой, бывает удобнее не распечатывать все дерево, а вывести имена дочерних элементов.

```{r}
names(xmlChildren(rootnode))
```
Работать со списком узлов можно как с обычным списком, то есть индексировать по имени или по номеру элемента при помощи квадратных скобок. Так мы достаем узел по имени:

```{r}
rootnode[["composition"]]
```

А так -- по индексу:

```{r}
rootnode[[2]]
```

Как и с обычными списками, мы можем использовать последовательности квадратных скобок:

```{r}
rootnode[[2]][["ingredient"]]
```
Но обычно нам нужен не элемент как таковой, а его содержание. 

```{r}
xmlValue(rootnode[[2]][["ingredient"]])
```

Значение атрибута тоже можно извлечь. Первым аргументом функции передаем название узла, вторым -- имя атрибута.

```{r}
xmlGetAttr(rootnode[[2]][["ingredient"]], "unit")
```
Как насчет того, чтобы применить эти операции ко всем ингредиентам? Вспоминаем, что это список.

```{r}
ingr_nodes <- xmlChildren(rootnode[[2]])
sapply(ingr_nodes, xmlValue)
```

C деревом XML можно работать и при помощи синтаксиса XPath. В большинстве случаев функция требует задать пространство имен, но в нашем случае оно не определено, поэтому передаем только дерево и путь до узла.

```{r}
ingr_nodes <- getNodeSet(rootnode, "//composition//ingredient")

ingr_nodes
```

Как вы понимаете, дальше можно применять все те же функции к каждому из найденных узлов при помощи `sapply`. Например, так:

```{r}
sapply(ingr_nodes, xmlGetAttr, "unit")
```
```{r}
sapply(ingr_nodes, xmlValue)
```

Значения атрибутов можно использовать в качестве фильтра. Допустим, нам нужны только те узлы, где значение атрибута unit = "стакан":

```{r}
getNodeSet(rootnode, "//composition//ingredient[@unit='стакан']")
```

Размер узла -- это число вложенных в него "детей".

```{r}
xmlSize(rootnode) == length(xmlChildren(rootnode))
```

Наконец, можно уточнить атрибуты узла:

```{r}
xmlAttrs(ingr_nodes[[1]])
```
</br>

:::{.task .code}
Используя xml с рецептами, создайте тиббл, в котором будут столбцы title, ingredient, unit и amount.
:::

</br>

Большая часть размеченных литературных корпусов хранится именно в формате XML. Это очень удобно, и вот почему: документы в формате XML, как и документы в формате HTML, содержат данные, заключенные в теги, но если в формате HTML теги определяют оформление данных, то в формате XML теги нередко *определяют структуру и смысл данных*. С их помощью мы можем достать из документа именно то, что нам интересно: определенную главу, речи конкретных персонажей, слова на иностранных языках и т.п. Добавлять и удалять разметку может любой пользователь в редакторе XML кода. По сути, это просто текст, хотя и причудливо (на первый взгляд) оформленный.

При этом в качестве универсального языка разметки в гуманитарных дисциплинах используется язык TEI [@skorinkin2016]. Корневой элемент в документах TEI называется TEI, внутри него располагается элемент teiHeader с метаинформацией о документе и элемент text. Последний содержит текст документа с элементами, определяющими его структурное членение. 

```{}
<TEI>
  <teiHeader></teiHeader>
  <text></text>
</TEI>
```

Пример оформления документа можно посмотреть [по ссылке](https://github.com/dracor-org/rusdracor/blob/main/tei/fonvizin-nedorosl.xml).

У teiHeader есть четыре главных дочерних элемента:

- fileDesc (описание документа c библиографической информацией)
- encodingDesc (описание способа кодирование первоисточника)
- profileDesc ("досье" на текст, например отправитель и получатель для писем, жанр, используемые языки, обстоятельства создания, место написания и т.п.)
- revisionDesc (история изменений документа)

В самом тексте язык TEI дает возможность представлять разные варианты (авторские, редакторские, корректорские и др.) Основным средством параллельного представления является элемент choice. Например, в [тексте Лукреция](https://github.com/PerseusDL/canonical-latinLit/blob/master/data/phi0550/phi001/phi0550.phi001.perseus-lat1.xml) вы можете увидеть такое:

```{}
sic calor atque <choice><reg>aer</reg><orig>aër</orig></choice> et venti caeca potestas
```

Здесь reg указывает на нормализованное написание, а orig -- на оригинальное. 

В качестве примера загрузим датасет "Пушкинского дома", подготовленный Д.А. Скоринкиным: ["Персонажи «Войны и мира» Л. Н. Толстого: вхождения в тексте, прямая речь и семантические роли"](https://dataverse.pushdom.ru/dataset.xhtml?persistentId=doi:10.31860/openlit-2022.1-C005). 


```{r}
filename = "files/War_and_Peace.xml"
doc <- xmlTreeParse(filename, useInternalNodes = T)
rootnode <- xmlRoot(doc)
```

Теперь можно внимательнее взглянуть на структуру xml. Корневой элемент расходится на две ветви. Полностью они нам пока не нужны, узнаем только имена:

```{r}
names(xmlChildren(rootnode)) 
```

Очевидно, что что-то для нас интересное будет спрятано в ветке text, глядим на нее (индексирование как для списков):

```{r}
names(xmlChildren(rootnode[["text"]])) 
```

Итак, текст делится на какие-то пять частей. Функция `xmlGetAttr()` позволяет узнать значение атрибута `type`: как выясняется, это том.

```{r}
# это список
divs_1 <-  rootnode[["text"]][["div"]] 
xmlGetAttr(divs_1, "type")
```

Как мы уже знаем, добраться до определенного узла можно не только путем индексирования, но и -- гораздо удобнее -- при помощи синтаксиса XPath. Для этого просто указываем путь до узла. Попробуем спуститься на два уровня ниже:

```{r}
divs <- getNodeSet(doc, "/tei:TEI//tei:text//tei:div//tei:div//tei:div", 
                     namespaces = c(tei = "http://www.tei-c.org/ns/1.0")) 

length(divs)
```

Обратите внимание, что в данном случае надо прямо прописать пространство имен (namespaces). Это можно посмотреть в самом xml, а можно воспользоваться специальной функцией:

```{r}
xmlNamespace(rootnode)
```

Итак, мы получили довольно длинный список (358 элементов), к которому снова можем применить `xmlGetAttr()`. Выясняем, что это все главы:

```{r}
unique(sapply(divs, xmlGetAttr, "type"))
```


Чтобы извлечь текст из конкретного узла, нужна функция `xmlValue`.

```{r}
chapter_1 <- xmlValue(divs[[1]])
```

Распечатывать весь текст первой главы не будем (это очень длинный вектор); разобъем текст на строки и выведем первую и последнюю:

```{r}
library(stringr)
chapter_lines <- str_split(chapter_1, pattern = "\n")

chapter_lines[[1]][[5]]
chapter_lines[[1]][[838]]
```

Первая и последняя реплика по-французски: все правильно! 

</br>

:::{.task .code}
Скачайте по [ссылке](https://raw.githubusercontent.com/dracor-org/rusdracor/main/tei/griboyedov-gore-ot-uma.xml) "Горе от ума" Грибоедова и преобразуйте xml в прямоугольный формат таким образом, чтобы для каждой реплики был указан акт, сцена и действующее лицо.
:::

</br>

Подбробнее о структуре XML документов и способах работы с ними вы можете прочитать в книгах: [@nolan2014] и [@xml2004]. 

### html

Язык **HTML** применяется для создания стандартных веб-страниц. Больше о работе с html вы узнаете из урока о веб-скрапинге.

## GutenbergR

Пакет `GutenbergR`[^05-import-7] поможет достать тексты из библиотеки [Gutenberg](https://www.gutenberg.org/ebooks/), но будьте осторожны: распознаны они не всегда хорошо и порой содержат много разного шума, например примечания редактора, номера страниц и т.п. В билингвах источник и перевод могут идти вперемешку. И если в XML подобные элементы будут окружены соответствующими тегами, которые позволят их легко отбросить при анализе, то Gutenberg дает вам сырой текст. Часто его надо хорошенько чистить при помощи регулярных выражений или даже вручную. 

Работать с метаданными GutenbergR вы уже научились, теперь можете пользоваться пакетом и для скачивания текстов. Сначала узнаем id нужных текстов
[^05-import-7]: <https://cran.r-project.org/web/packages/gutenbergr/vignettes/intro.html>

```{r}
library(gutenbergr)

caesar <- gutenberg_works(author == "Caesar, Julius", languages = "la") 

caesar 
```

Чтобы извлечь отдельный текст (тексты):

```{r}
de_bello_gallico <- gutenberg_download(218, meta_fields = "title", mirror = "ftp://mirrors.xmission.com/gutenberg/")
de_bello_gallico
```

::: infobox
Существует несколько зеркал библиотеки Gutenberg, и, если при выполнении функции `gutenberg_download()` возникает ошибка "could not download a book at <http://aleph.gutenberg.org/>", то следует использовать аргумент mirror. Список зеркал доступен по ссылке: <https://www.gutenberg.org/MIRRORS.ALL>
:::
